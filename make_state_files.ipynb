{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is meant to convert the NLDAS data into NetCDF format\n",
    "# This will be used by the MetSim algorithm to create the radiation/vapor pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModified on Fri June 5 2020\\n@author: Jonathan Frame\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Modified on Fri June 5 2020\n",
    "@author: Jonathan Frame\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "from metsim import MetSim\n",
    "import netCDF4 as nc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/home/NearingLab/projects/jmframe/CAMELS_synthData/nldas_forcing/'\n",
    "data_dir_txt = '/home/NearingLab/projects/jmframe/CAMELS_synthData/nldas_forcing_txt/'\n",
    "data_dir_nc = '/home/NearingLab/projects/jmframe/CAMELS_synthData/nldas_forcing_nc/'\n",
    "state_dir_nc = '/home/NearingLab/projects/jmframe/CAMELS_synthData/state_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store all attributes. Really just need basin area, but the rest might come in handy.\n",
    "att_path = \"/home/NearingLab/data/camels_attributes_v2.0/camels_all.txt\"\n",
    "attributes = pd.read_csv(att_path, sep=\";\")\n",
    "attributes.set_index('gauge_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prefixes for all the forcing data files.\n",
    "prefix_dict = {'{:02}'.format(pf):[] for pf in range(1, 19)}\n",
    "for sub_dir_name in glob.glob('/home/NearingLab/projects/jmframe/CAMELS_synthData/nldas_forcing_txt/*'):\n",
    "    if sub_dir_name == 'readme_git.md':\n",
    "        continue\n",
    "    for file_path in glob.glob(sub_dir_name+'/*'):\n",
    "        prefix = sub_dir_name.split('/')[7]\n",
    "        temp_basin_id = re.split('_|/', file_path)[11]\n",
    "        if prefix in prefix_dict.keys():\n",
    "            prefix_dict[prefix].append(temp_basin_id)\n",
    "attributes['prefix'] = [np.nan]*attributes.shape[0]\n",
    "for k in prefix_dict.keys():\n",
    "    for b in prefix_dict[k]:\n",
    "        attributes.loc[int(b), 'prefix'] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_txt_sample = data_dir_txt + '01/01013500_lump_nldas_forcing_leap.txt'\n",
    "data_txt_sample = pd.read_csv(path_data_txt_sample, engine='python', header=3, sep='\\t')\n",
    "nldas_time = [dt.datetime(1980, 1, 1) + dt.timedelta(days=day) \n",
    "                  for day in range(data_txt_sample.shape[0])]\n",
    "nldas_doy = [nldas_time[t].timetuple().tm_yday for t in range(len(nldas_time))]\n",
    "state_time = [dt.datetime(1979, 1, 1) + dt.timedelta(days=day) \n",
    "                  for day in range(366)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_LAT_LON_FROM_ATTRIBUTES(attributes, basin_id_int):\n",
    "    return [attributes.loc[basin_id_int,'gauge_lat'], attributes.loc[basin_id_int,'gauge_lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUMMARIZE_STATE_DATA(basinID):\n",
    "    basin_id_int = int(basinID)\n",
    "    basin_id_str = \"{:08}\".format(basin_id_int)\n",
    "    latCatchment , lonCatchment = GET_LAT_LON_FROM_ATTRIBUTES(attributes, basin_id_int)\n",
    "    \n",
    "    # initialize the NetCDF forcing data file.\n",
    "    data_dir_txt = '/home/NearingLab/projects/jmframe/CAMELS_synthData/nldas_forcing_txt/'\n",
    "    data_dir_nc = '/home/NearingLab/projects/jmframe/CAMELS_synthData/nldas_forcing_nc/'\n",
    "    prefix = attributes.loc[basin_id_int, 'prefix']\n",
    "    path_data_txt = data_dir_txt + prefix + '/' + basin_id_str + '_lump_nldas_forcing_leap.txt'\n",
    "    data_txt = pd.read_csv(path_data_txt, engine='python', header=3, sep='\\t')\n",
    "    data_txt['date_time'] = nldas_time\n",
    "    data_txt['doy'] = nldas_doy\n",
    "    data_ave = data_txt.groupby('doy').mean()\n",
    "    return data_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAKE_STATE_FILES(basinID, data_averages):\n",
    "    basin_id_int = int(basinID)\n",
    "    basin_id_str = \"{:08}\".format(basin_id_int)\n",
    "    latCatchment , lonCatchment = GET_LAT_LON_FROM_ATTRIBUTES(attributes, basin_id_int)\n",
    "\n",
    "    #BEGIN #######################################################################\n",
    "    #BEGIN #  WRITE DATA TO THE NETCDF state DATA FILE   #######################\n",
    "    #BEGIN #######################################################################\n",
    "\n",
    "    stateDataName = state_dir_nc + basin_id_str + '_state.nc'\n",
    "    state = nc.Dataset(stateDataName, 'w', format='NETCDF4_CLASSIC')\n",
    "    state.title = basin_id_str +' _state'\n",
    "    state.description = 'State file for basin '+ basin_id_str + ' in the CAMELS catchments'\n",
    "\n",
    "    state.createDimension('lat', 1)\n",
    "    state.createDimension('lon', 1)\n",
    "    state.createDimension('time', size=366)\n",
    "\n",
    "    ### createVareables in new data set\n",
    "    state.createVariable('Prec', np.int32, ('time',))\n",
    "    state.variables['Prec'].units = 'mm'\n",
    "    state.variables['Prec'].long_name = 'Precipitation'\n",
    "    #state.variables['Prec'].v_type = 'scalarv'\n",
    "    state.variables['Prec'][:] = np.array(data_averages['PRCP(mm/day)'])\n",
    "\n",
    "    state.createVariable('Tmax', np.float32, ('time',))\n",
    "    state.variables['Tmax'].units = 'C' \n",
    "    state.variables['Tmax'].longname = \"Daily maximum temperature\"\n",
    "    #state.variables['Tmax'].v_type = 'scalarv'\n",
    "    state.variables['Tmax'][:] = np.array(data_averages['Tmax(C)'])\n",
    "    \n",
    "    state.createVariable('Tmin', np.float32, ('time',))\n",
    "    state.variables['Tmin'].units = 'C'\n",
    "    state.variables['Tmin'].longname = \"Daily minimum temperature\"\n",
    "    #state.variables['Tmin'].v_type = 'scalarv'\n",
    "    state.variables['Tmin'][:] = np.array(data_averages['Tmin(C)'])\n",
    "    \n",
    "    state.createVariable('latitude', np.float32, ('lat',))\n",
    "    state.variables['latitude'].units = 'degrees_north'\n",
    "    state.variables['latitude'].long_name = 'latitude'\n",
    "    state.variables['latitude'].axis = 'Y'\n",
    "    state.variables['latitude'][:] = latCatchment\n",
    "\n",
    "    state.createVariable('longitude', np.float32, ('lon',))\n",
    "    state.variables['longitude'].units = 'degrees-east'\n",
    "    state.variables['longitude'].long_name = 'longitude'\n",
    "    state.variables['longitude'].axis = 'X'\n",
    "    state.variables['longitude'][:] = lonCatchment\n",
    "\n",
    "    state.createVariable('time', np.float64, ('time',))\n",
    "    state.variables['time'].units = 'hours since 2000-01-01 00:00:00'\n",
    "    state.variables['time'].long_name = \"local time at grid location\"\n",
    "    state.variables['time'].calendar = 'standard'\n",
    "    state.variables['time'][:] = nc.date2num(state_time, \n",
    "                                          units='hours since 2000-01-01 00:00', calendar='standard')\n",
    "    \n",
    "    state.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_state_files = True\n",
    "if make_state_files:\n",
    "    for b in attributes.index.values:\n",
    "        data_averages = SUMMARIZE_STATE_DATA(b)\n",
    "        MAKE_STATE_FILES(b, data_averages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
